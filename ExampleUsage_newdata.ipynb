{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350793aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la imagen:  (768, 768)\n",
      "Tipo de la imagen:  uint8\n",
      "Rango de valores de la imagen:  0 255\n",
      "Número de canales:  2\n",
      "Dimensiones de la imagen:  (768, 768)\n",
      "Tipo de la imagen:  uint8\n",
      "Rango de valores de la imagen:  0 255\n",
      "Número de canales:  2\n"
     ]
    }
   ],
   "source": [
    "#Analyze data\n",
    "\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "file = \"example_data/image1.png\"\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#Imprimo dimensiones de la imagen, tipo y rangos de valores\n",
    "print(\"Dimensiones de la imagen: \", img.shape)\n",
    "print(\"Tipo de la imagen: \", img.dtype)\n",
    "print(\"Rango de valores de la imagen: \", np.min(img), np.max(img))\n",
    "print(\"Número de canales: \", img.ndim)\n",
    "\n",
    "\n",
    "#Cargo imagen de ejemplo de pilar\n",
    "file = \"example_data/image4_edited.png\"\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "temp_file = 'example_data/temp_image.png'\n",
    "cv2.imwrite(temp_file, img)\n",
    "\n",
    "file = temp_file\n",
    "\n",
    "#Imprimo dimensiones de la imagen, tipo y rangos de valores\n",
    "print(\"Dimensiones de la imagen: \", img.shape)\n",
    "print(\"Tipo de la imagen: \", img.dtype)\n",
    "print(\"Rango de valores de la imagen: \", np.min(img), np.max(img))\n",
    "print(\"Número de canales: \", img.ndim)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304ce83-fa3d-46a4-9fc2-26c62f963573",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'choroidalyze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchoroidalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Choroidalyzer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# This initialises choroidalyzer. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# It will try to automatically download the model weights from github the first time you run it. \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lupam\\OneDrive\\Escritorio\\GitHub\\BamTech_choroidalyzer\\src\\models\\choroidalyze\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Choroidalyzer\n",
      "File \u001b[1;32mc:\\Users\\lupam\\OneDrive\\Escritorio\\GitHub\\BamTech_choroidalyzer\\src\\models\\choroidalyze\\inference.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchoroidalyze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchoroidalyze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_measurement\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_img_transforms\u001b[39m():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'choroidalyze'"
     ]
    }
   ],
   "source": [
    "from choroidalyze import Choroidalyzer\n",
    "import cv2\n",
    "\n",
    "\n",
    "# This initialises choroidalyzer. \n",
    "# It will try to automatically download the model weights from github the first time you run it. \n",
    "choroidalyzer = Choroidalyzer()\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "file = \"example_data/image4_edited.png\"\n",
    "#Convierto imagen a blanco y negro\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "#Guardo la nuena imagen\n",
    "temp_file = 'example_data/temp_image.png'\n",
    "cv2.imwrite(temp_file, img)\n",
    "file = temp_file\n",
    "\n",
    "# basic useage: get the metrics\n",
    "metrics = choroidalyzer.analyze(file) #, scale=(11.49, 3.87)\n",
    "print(metrics)\n",
    "\n",
    "# choroidalyzer also has a basic plotting function to inspect segmentation outputs\n",
    "choroidalyzer.predict_and_plot(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72092bdd-a93d-45ea-bc72-5cbed0bb17a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0382c-79f9-4ade-b817-8cbd03b04a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The segmentation has 3 channels: first channel is region, second vessels, third fovea\n",
      "['region', 'vessel', 'fovea']\n",
      "torch.Size([3, 768, 768])\n",
      "Note that the segmentations by default are not binarized, so you can access the raw pixel-wise probabilities\n"
     ]
    }
   ],
   "source": [
    "# you can also access just the segmentations\n",
    "raw_segmentations = choroidalyzer.predict(file)\n",
    "print('The segmentation has 3 channels: first channel is region, second vessels, third fovea')\n",
    "print(choroidalyzer.outputs)\n",
    "print(raw_segmentations.shape)\n",
    "print('Note that the segmentations by default are not binarized, so you can access the raw pixel-wise probabilities')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BamTech_choroidalyzer3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
