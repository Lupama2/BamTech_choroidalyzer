{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze data\n",
    "\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "file = \"example_data/image1.png\"\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#Imprimo dimensiones de la imagen, tipo y rangos de valores\n",
    "print(\"Dimensiones de la imagen: \", img.shape)\n",
    "print(\"Tipo de la imagen: \", img.dtype)\n",
    "print(\"Rango de valores de la imagen: \", np.min(img), np.max(img))\n",
    "print(\"Número de canales: \", img.ndim)\n",
    "\n",
    "\n",
    "#Cargo imagen de ejemplo de pilar\n",
    "file = \"example_data/image4_edited.png\"\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "temp_file = 'example_data/temp_image.png'\n",
    "cv2.imwrite(temp_file, img)\n",
    "\n",
    "file = temp_file\n",
    "\n",
    "#Imprimo dimensiones de la imagen, tipo y rangos de valores\n",
    "print(\"Dimensiones de la imagen: \", img.shape)\n",
    "print(\"Tipo de la imagen: \", img.dtype)\n",
    "print(\"Rango de valores de la imagen: \", np.min(img), np.max(img))\n",
    "print(\"Número de canales: \", img.ndim)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choroidalyze import Choroidalyzer\n",
    "import cv2\n",
    "\n",
    "\n",
    "# This initialises choroidalyzer. \n",
    "# It will try to automatically download the model weights from github the first time you run it. \n",
    "choroidalyzer = Choroidalyzer()\n",
    "\n",
    "#Cargo imagen de ejemplo\n",
    "file = \"example_data/image4_edited.png\"\n",
    "#Convierto imagen a blanco y negro\n",
    "img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "#Guardo la nuena imagen\n",
    "temp_file = 'example_data/temp_image.png'\n",
    "cv2.imwrite(temp_file, img)\n",
    "file = temp_file\n",
    "\n",
    "# basic useage: get the metrics\n",
    "metrics = choroidalyzer.analyze(file) #, scale=(11.49, 3.87)\n",
    "print(metrics)\n",
    "\n",
    "# choroidalyzer also has a basic plotting function to inspect segmentation outputs\n",
    "choroidalyzer.predict_and_plot(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BamTech_choroidalyzer3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
